# day 3

## 一、隐语义模型与矩阵分解

针对协同过滤算法

缺点：没有完全利用物品/用户的属性，仅仅利用了用户和物品的交互信息---可解释性强，直观；处理系数矩阵的能力弱

矩阵分解模型（Matrix Factorization，MF）隐语义模型，用更稠密的隐向量表示用户和物品

## 二、隐语义模型

### 1. 基本概念

最早用于找到文本的隐含语义，2006年，用于推荐，核心思想是通过隐含特征（latent factor）联系用户兴趣和物品，基于用户的行为找出潜在的主题和分类，然后对item进行自动聚类，划分到不同类、主题中

e.g. ---from 项亮《推荐系统实践》

> 若已知A，B两个用户在豆瓣的读书列表，看出A涉及侦探小说、科普图书以及计算机技术书，B兴趣集中在数学和机器学习方面，如何给A/B推荐书籍呢
>
> 协同过滤算法：
>
> - UserCF：找到兴趣相似用户，把相似用户喜欢的书推给用户
> - ItemCF：如用户B喜欢数据挖掘的书，就给他推荐机器学习或模式识别的书
>
> 隐语义模型：
>
> 通过某些角度把用户兴趣和这些书做归类，当新用户发现后，首先的到他的兴趣分类，然后从该分类中挑选他可能喜欢的书

不同之处：隐含特征：内容，作者，年份，主题

![王喆老师《深度学习推荐系统》](https://i.pinimg.com/originals/5d/4d/ff/5d4dff3377dc7b002343908b81a61c6a.png)

### 2. **e.g.** 音乐评分例子

每个人对不同的元素偏好不同，希望找到下面的两个矩阵

a. 潜在因子 -- 用户矩阵Q，表示不同用户对于不同元素的偏好程度，1表示很喜欢了

|      | 小清新 | 重口味 | 优雅 | 伤感 | 五月天 |
| ---- | ------ | ------ | ---- | ---- | ------ |
| jack | 0.6    | 0.8    | 0.1  | 0.1  | 0.7    |
| mike | 0.1    | 0      | 0.9  | 0.1  | 0.2    |
| lily | 0.5    | 0.7    | 0.9  | 0.9  | 0      |

b. 潜在因子 -- 音乐矩阵P 表示音乐的元素成分

|       | 小清新 | 重口味 | 优雅 | 伤感 | 五月天 |
| ----- | ------ | ------ | ---- | ---- | ------ |
| 音乐A | 0.9    | 0.1    | 0.2  | 0.4  | 0      |
| 音乐B | 0.5    | 0.6    | 0.1  | 0.9  | 1      |
| 音乐C | 0      | 0.6    | 0.1  | 0.2  | 0      |

从而得到张三对音乐A的喜爱程度：
$$
张三_{小清新} * 音乐A_{小清新} + 张三_{重口味} * 音乐A_{重口味} + 张三_{优雅} * 音乐A_{优雅} + ...... = 0.6 * 0.9 + 0.8 * 0.1 + 0.1 * 0.2 + 0.1 * 0.4 + 0.7 * 0 = 0.69
$$
对应两个隐向量

|      | 小清新 | 重口味 | 优雅 | 伤感 | 五月天 |
| ---- | ------ | ------ | ---- | ---- | ------ |
| 张三 | 0.6    | 0.8    | 0.1  | 0.1  | 0.7    |

|       | 小清新 | 重口味 | 优雅 | 伤感 | 五月天 |
| ----- | ------ | ------ | ---- | ---- | ------ |
| 音乐A | 0.9    | 0.1    | 0.2  | 0.4  | 0      |

同理得到最终的评分矩阵

|      | 音乐A | 音乐B                                                     | 音乐C    | 音乐D |
| ---- | ----- | --------------------------------------------------------- | -------- | ----- |
| jack | 0.68  | **1.58**                                                  | 0.28     | 0.51  |
| mike | 0.31  | 0.438&2&4\2&3&9\10&\dfrac{3}{4}&\sqrt{3}\a&b&c\end{array} | **0.47** | 0.11  |
| lily | 1.06  | **1.57**                                                  | 0.73     | 0.69  |

标记粗体表示用户没有打分，通过隐向量计算得到：

通过隐含特征对用户的兴趣和音乐进行分类，其实就是找到：每个用户和每个音乐的隐向量表达形式：Embedding的原理也是这样，通过隐向量反映用户的兴趣和物品的风格

是协同过滤的延伸，用隐向量表示用户和物品的相似性

**然而**：很难找到这样的隐特诊，事实上只有用户的评分矩阵：

如下：

| User/Item | 1    | 2    | 3    | 4    | 5    |
| --------- | ---- | ---- | ---- | ---- | ---- |
| 1         | 5    | 4    | 4.5  | ?    | 3.9  |
| 2         | ?    | 4.5  | ?    | 4.5  | ?    |
| 3         | 4.5  | ?    | 4.4  | 4    | 4    |
| 4         | ?    | 4.8  | ?    | ?    | 4.5  |
| 5         | 4    | ?    | 4.5  | 5    | ?    |

稀疏矩阵，尝试填充会发生长尾问题，这个时候用到矩阵分解来解决矩阵稀疏的问题

**目的：基于稀疏的评分矩阵去寻找上面例子中的关于用户兴趣和物品的隐向量表达，然后把这个评分矩阵分解成P和Q的两个矩阵乘积的心事，然后基于这两个矩阵去预测某用户对某物品的评分，然后就基于这个评分去推荐**

## 三、矩阵分解算法的原理

矩阵分解：通过分解协同过滤共现矩阵来得到用户和物品的隐向量

![矩阵分解原理](https://i.pinimg.com/originals/f5/16/43/f51643eb706763d74725aaadc15535d8.png)
$$
共享矩阵R：m\times n = 用户矩阵U： m \times k \cdot 物品矩阵V:k \times n
$$

$$
m是用户数量，n是物品数量，k是隐向量唯独，k的大小决定了隐向量表达能力的强弱，越大则表达信息越强
$$

这里的隐含特征不可解释了，不知道具体含义

如果得到了用户矩阵和物品矩阵
$$
下计算用户 u 对物品 i 的评分，p_u就是用户u的隐向量(行向量)，q_i是物品的隐向量(列向量)
$$

$$
 \operatorname{Preference}(u, i)=r_{u i}=p_{u}^{T} q_{i}=\sum_{f=1}^{F} p_{u, k} q_{k,i}
$$

$$
p_{u,k}度量的是用户u的兴趣和第k个隐类的关系，而q_{k,i}度量了第k个隐类和物品i的关系
$$

## 四、矩阵分解算法的求解

特征值分解(EVD):要求分解的矩阵是方阵

奇异值分解(SVD)：需要原始矩阵是稠密的，即要对缺失的元素进行填充，导致计算复杂度很高

## 五、basic SVD

Funk-SVD，被Koren称为Latent Factor Model：把求解这两个矩阵的参数问题换成一个最优化问题，可以通过训练集里面的观察值利用最小值来学习用户矩阵和物品矩阵

随机初始化
$$
现有r_{u,i}，但是没有p_{u}^{T}q_{i}，需要随机初始化一个用户矩阵和物品矩阵
$$

$$
随机初始化得到p_{u}^{T} q_{i}后，计算一个猜测的\hat{r}_{u,i}，\hat{r}_{u,i}=p_{u}^{T} q_{i} 
$$

$$
猜测和真实值间产生误差： e_{u i}=r_{u i}-\hat{r}_{u i}
$$

有了误差就可以计算总的误差平方和
$$
\operatorname{SSE}=\sum_{u, i} e_{u i}^{2}=\sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{k, i}\right)^{2}
$$
通过训练，降低损失SSE，就可以得到两个矩阵参数，从而转化原问题为最优化问题，目标函数为：
$$
\operatorname{SSE}=\sum_{u, i} e_{u i}^{2}=\sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{k, i}\right)^{2}
$$
有了目标函数，使用梯度下降算法降低损失，则需要对目标函数求偏导，得到梯度，导数推导：
$$
对\operatorname{SSE}=\sum_{u, i} e_{u i}^{2}=\sum_{u, i}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{k,i}\right)^{2}
$$

$$
\frac{\partial}{\partial p_{u,k}} S S E=\frac{\partial}{\partial p_{u,k}}\left(e_{u i}^{2}\right) =2e_{u i} \frac{\partial}{\partial p_{u,k}} e_{u i}=2e_{u i} \frac{\partial}{\partial p_{u,k}}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{k,i}\right)=-2e_{u i} q_{k,i}
$$

$$
 然后求SSE在q_{k,i}处(也就是V矩阵的第k行i列）的梯度
$$

$$
\frac{\partial}{\partial q_{k,i}} S S E=\frac{\partial}{\partial p_{k,i}}\left(e_{u i}^{2}\right) =2e_{u i} \frac{\partial}{\partial p_{k,i}} e_{u i}=2e_{u i} \frac{\partial}{\partial p_{k,i}}\left(r_{u i}-\sum_{k=1}^{K} p_{u,k} q_{k,i}\right)=-2e_{u i} p_{u,k}
$$

去掉常数项
$$
\operatorname{SSE}=\frac{1}{2} \sum_{u, i} e_{u i}^{2}
$$
梯度下降算法的梯度更新：
$$
\begin{cases}p_{u, k}=p_{u,k}-\eta (-e_{ui}q_{k,i})=p_{u,k}+\eta e_{ui}q_{k,i}\\q_{k, i}=q_{k, i}-\eta (-e_{ui}p_{u,k})=q_{k, i}+\eta e_{ui}p_{u,k}\end{cases}
$$
然而当参数很多，即矩阵很大的时候容易陷入过拟合的困境，需要目标函数上加上正则化的损失---->RSVD

实际过程中，只考虑下面这个公式是不够的，需要考虑其他因素，如一个评分系统，有些固有的属性与用户、物品都没有直接的关系：
$$
\hat{r}_{u,i}=p_{u}^{T} q_{i}
$$
基于这一点，Netfix Prize提出了另一种LFM，在原来的基础上加上了偏置项，来消除用户和物品打分的误差，预测公式如下：
$$
\hat{r}_{u i}=\mu+b_{u}+b_{i}+p_{u}^{T} \cdot q_{i}
$$
这三个偏置项的作用分别如下：

> u,i$\mu$ : 训练集中所有记录的评分的全局平均数，由于网站定位和销售物品不同，网站的真题评分分布会显示差异，有的网站中用户普遍爱打低分，全局平均数表示网站本身对用户评分的影响
>
> $b_u$ : 用户偏差系数，可以使用用户u所有评分的均值，也可以作为训练参数。这一项表示了物品接受的评分中和用户没有关系的因素。如有的用户要求更严格
>
> $b_i$ : 物品偏差系数，可以使用物品i收到的所有评分的均值，也可以作为训练参数。这一项表示物品接受的评分中和用户没关系的因素。比如有的物品质量本身就普遍偏高

加入打分偏差后，矩阵分解得到的隐向量更能反应不同用户对不同物品的真实态度的差异，更能捕捉评价数据中有家室的信息，从而避免推荐结果有偏差。此时的SSE会更新公式：
$$
\begin{array}{l}
\operatorname{SSE} = \frac{1}{2} \sum_{u, i} e_{u,i}^{2} + \frac{1}{2} \lambda \sum_{u}\left|\boldsymbol{p}_{u}\right|^{2}
+ \frac{1}{2} \lambda \sum_{i}\left|\boldsymbol{q}_{i}\right|^{2}
+ \frac{1}{2} \lambda \sum_{u} \boldsymbol{b}_{u}^{2}
+ \frac{1}{2} \lambda \sum_{u} \boldsymbol{b}_{i}^{2} 
\\ 
= \frac{1}{2} \sum_{u, i}\left(\boldsymbol{r}_{u,i}
- \boldsymbol{\mu}-\boldsymbol{b}_{u}-\boldsymbol{b}_{i}
- \sum_{k = 1}^{K} \boldsymbol{p}_{u,k} \boldsymbol{q}_{k i}\right)^{2}
+ \frac{1}{2} \lambda \sum_{u}\left|\boldsymbol{p}_{u}\right|^{2}
+ \frac{1}{2} \lambda \sum_{i}\left|\boldsymbol{q}_{i}\right|^{2}
+ \frac{\mathbf{1}}{2} \lambda \sum_{u} \boldsymbol{b}_{u}^{2}
+ \frac{1}{2} \lambda \sum_{u} \boldsymbol{b}_{i}^{2} 
\end{array}
$$

$$
若此时将b_u和b_i作为训练参数的话，则他两的梯度是：
$$

$$
\frac{\partial}{\partial b_{u}} SSE = -e_{u i}+\lambda b_{u}
\\
\frac{\partial}{\partial b_{i}} S S E=-e_{u i}+\lambda b_{i}
$$

$$
\begin{aligned} \boldsymbol{b}_{\boldsymbol{u}}&=\boldsymbol{b}_{\boldsymbol{u}}+\boldsymbol{\eta}\left(\boldsymbol{e}_{\boldsymbol{u},\boldsymbol{i}}-\lambda \boldsymbol{b}_{\boldsymbol{u}}\right) \\ \boldsymbol{b}_{\boldsymbol{i}} &=\boldsymbol{b}_{\boldsymbol{i}}+\boldsymbol{\eta}\left(\boldsymbol{e}_{\boldsymbol{u},\boldsymbol{i}}-\lambda \boldsymbol{b}_{\boldsymbol{i}}\right) \end{aligned}
$$

## 六、编程实现

用矩阵分解的方法实现协同过滤那篇的例子：预测Alice对物品5的评分，来解读矩阵分解的预测推荐过程：

|       | 物品1 | 物品2 | 物品3 | 物品4 | 物品5  |
| ----- | ----- | ----- | ----- | ----- | ------ |
| Alice | 5     | 3     | 4     | 4     | **？** |
| 用户1 | 3     | 1     | 2     | 3     | 3      |
| 用户2 | 4     | 3     | 4     | 3     | 5      |
| 用户3 | 3     | 3     | 1     | 5     | 4      |
| 用户4 | 1     | 5     | 5     | 2     | 1      |

SVD：

> 1. 初始化用户矩阵和物品矩阵，P的维度是`[users_num, F]`，Q的维度是 `[item_num, F]`， F是影响量的维度，也就是把通过隐向量的方式把用户的兴趣和F的特点关联了起来。初始化方式很多，根据经验得到随机数需要和1/sqrt(F)成正比
> 2. 通过这两个矩阵，根据用户已经打分的数据去更新参数，这就是训练模型的过程，即遍历用户，拿到用户和物品的隐向量，然后两者相乘加上偏置就是预测的评分，这与真实评分的差距，就根据梯度下降进行参数的更新。

带有偏置项和正则项的SVD算法

```python
class SVD():
    def __init__(self, rating_data, F=5, alpha=0.1, lmbda=0.1, max_iter=100):
        self.F = F           # 这个表示隐向量的维度
        self.P = dict()          #  用户矩阵P  大小是[users_num, F]
        self.Q = dict()     # 物品矩阵Q  大小是[item_nums, F]
        self.bu = dict()   # 用户偏差系数
        self.bi = dict()    # 物品偏差系数
        self.mu = 0.0        # 全局偏差系数
        self.alpha = alpha   # 学习率
        self.lmbda = lmbda    # 正则项系数
        self.max_iter = max_iter    # 最大迭代次数
        self.rating_data = rating_data # 评分矩阵
        
        # 初始化矩阵P和Q, 方法很多， 一般用随机数填充， 但随机数大小有讲究， 根据经验， 随机数需要和1/sqrt(F)成正比
        cnt = 0    # 统计总的打分数， 初始化mu用
        for user, items in self.rating_data.items():
            self.P[user] = [random.random() / math.sqrt(self.F)  for x in range(0, F)]
            self.bu[user] = 0
            cnt += len(items) 
            for item, rating in items.items():
                if item not in self.Q:
                    self.Q[item] = [random.random() / math.sqrt(self.F) for x in range(0, F)]
                    self.bi[item] = 0
        self.mu /= cnt
        
    # 有了矩阵之后， 就可以进行训练, 这里使用随机梯度下降的方式训练参数P和Q
    def train(self):
        for step in range(self.max_iter):
            for user, items in self.rating_data.items():
                for item, rui in items.items():
                    rhat_ui = self.predict(user, item)   # 得到预测评分
                    # 计算误差
                    e_ui = rui - rhat_ui
                    
                    self.bu[user] += self.alpha * (e_ui - self.lmbda * self.bu[user])
                    self.bi[item] += self.alpha * (e_ui - self.lmbda * self.bi[item])
                    # 随机梯度下降更新梯度
                    for k in range(0, self.F):
                        self.P[user][k] += self.alpha * (e_ui*self.Q[item][k] - self.lmbda * self.P[user][k])
                        self.Q[item][k] += self.alpha * (e_ui*self.P[user][k] - self.lmbda * self.Q[item][k])
                    
            self.alpha *= 0.1    # 每次迭代步长要逐步缩小
    
    # 预测user对item的评分， 这里没有使用向量的形式
    def predict(self, user, item):
        return sum(self.P[user][f] * self.Q[item][f] for f in range(0, self.F)) + self.bu[user] + self.bi[item] + self.mu   
```

建立字典存放数据，解决矩阵稀疏比较好的方式

```python
# 定义数据集， 也就是那个表格， 注意这里我们采用字典存放数据， 因为实际情况中数据是非常稀疏的， 很少有情况是现在这样
def loadData():
    rating_data={1: {'A': 5, 'B': 3, 'C': 4, 'D': 4},
           2: {'A': 3, 'B': 1, 'C': 2, 'D': 3, 'E': 3},
           3: {'A': 4, 'B': 3, 'C': 4, 'D': 3, 'E': 5},
           4: {'A': 3, 'B': 3, 'C': 1, 'D': 5, 'E': 4},
           5: {'A': 1, 'B': 5, 'C': 5, 'D': 2, 'E': 1}
          }
    return rating_data
 
# 接下来就是训练和预测
rating_data = loadData()
basicsvd = SVD(rating_data, F=10)
basicsvd.train()
for item in ['E']:
    print(item, basicsvd.predict(1, item))
 
## 结果：
E 3.252210242858994
```

最后得到的预测评分和隐向量的维度，训练次数，训练方式有关。

## 七、课后思考

### 1. 矩阵分解算法后续改进有哪些，是为了解决什么问题

RSVD：消除用户和物品的打分偏差

### 2. 矩阵分解的优缺点

优点：

> 泛化能力强，克服稀疏问题
>
> 空间复杂度低（隐向量形式存放用户与物品，不用构造相似度矩阵，复杂度n方到（n + m) * F
>
> 更好的扩展性和灵活性：用户和物品相似度矩阵和Embedding思想相近，因此矩阵分解结果易于和其他特征组合拼接，也可以很好的和深度学习结合

缺点：

> 依旧只用到了评分矩阵，没有考虑用户特征，物品特征和上下文特征，缺失了很多有效信息，对缺乏用户历史行为时，推荐无效。

未解决这个问题：逻辑回归模型和后续的因子分解机模型，能够融合不同特征，因此得到更广泛的应用

